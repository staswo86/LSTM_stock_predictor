{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df42ec2-349c-4983-9992-fb18d5570000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def read_data_function(file_name):\n",
    "    data_frame = pd.read_csv(file_name, sep = \",\")\n",
    "    data_frame = data_frame[[\"date\", \"open\"]]\n",
    "    data_frame[\"date\"] = pd.to_datetime(data_frame[\"date\"], format = \"%Y-%m-%d\")\n",
    "    data_frame.index = data_frame.pop(\"date\")\n",
    "    #scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "    #stock_price_val = data_frame[\"open\"].values.reshape(-1,1)\n",
    "    #data_frame[\"open\"] = scaler.fit_transform(stock_price_val)\n",
    "    \n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f178308f-2d6a-4195-9a11-7ed98f8e8a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-08</th>\n",
       "      <td>15.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-11</th>\n",
       "      <td>14.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-12</th>\n",
       "      <td>14.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-13</th>\n",
       "      <td>14.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-14</th>\n",
       "      <td>14.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>76.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>77.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>76.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>72.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>72.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619040 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             open\n",
       "date             \n",
       "2013-02-08  15.07\n",
       "2013-02-11  14.89\n",
       "2013-02-12  14.45\n",
       "2013-02-13  14.30\n",
       "2013-02-14  14.94\n",
       "...           ...\n",
       "2018-02-01  76.84\n",
       "2018-02-02  77.53\n",
       "2018-02-05  76.64\n",
       "2018-02-06  72.74\n",
       "2018-02-07  72.70\n",
       "\n",
       "[619040 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_data_function(\"all_stocks_5yr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25cf922e-ee03-4b27-b329-8f8a66a5cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def data_prep_function(sequence_dataset,window_size):\n",
    "    #sequence_dataset = [np.array(sequence_dataset[i*sliding_window_size: (i + 1) * sliding_window_size]) for i in range(len(sequence_dataset) // sliding_window_size)]\n",
    "    #X = np.array([sequenc_dataset[i: i + num_steps] for i in range(len(sequence_dataset) - sliding_window_size)])\n",
    "    #y = np.array([sequence_dataset[i + num_steps] for i in range(len(sequence_dataset) - sliding_window_size)])\n",
    "    for i in range(1, window_size + 1):\n",
    "        sequence_dataset[f\"open-{i}\"] = sequence_dataset[\"open\"].shift(i)\n",
    "\n",
    "\n",
    "    sequence_dataset.dropna(inplace = True)\n",
    "\n",
    "\n",
    "    return sequence_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e97bfe7-f753-44b4-8446-9c3d671b8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data_function(\"all_stocks_5yr.csv\")\n",
    "window_data = data_prep_function(data, window_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9715a539-4286-4660-b34f-e8415dd6f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def matrix_formatting_and_normalize_dataset(sliding_window_dataset):\n",
    "    sliding_window_dataset = sliding_window_dataset.to_numpy()\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(sliding_window_dataset)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3f0a29-bab0-45db-9821-cf58ad8e4f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00586571, 0.00585102, 0.0058755 , ..., 0.00628189, 0.00649732,\n",
       "        0.00658545],\n",
       "       [0.00564048, 0.00586571, 0.00585102, ..., 0.00620844, 0.00628189,\n",
       "        0.00649732],\n",
       "       [0.00570903, 0.00564048, 0.00586571, ..., 0.0065218 , 0.00620844,\n",
       "        0.00628189],\n",
       "       ...,\n",
       "       [0.03673166, 0.03716742, 0.03682958, ..., 0.03747589, 0.03705481,\n",
       "        0.03674634],\n",
       "       [0.03482212, 0.03673166, 0.03716742, ..., 0.03762767, 0.03747589,\n",
       "        0.03705481],\n",
       "       [0.03480253, 0.03482212, 0.03673166, ..., 0.03812709, 0.03762767,\n",
       "        0.03747589]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_data_function(\"all_stocks_5yr.csv\")\n",
    "window_data = data_prep_function(data, window_size = 10)\n",
    "matrix_formatting_and_normalize_dataset(window_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fe15dc1-03f1-4f0a-88fe-278190d5c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "def feature_target_modeling(dataset) -> tuple[TensorDataset]:\n",
    "    X = dataset[:, 1:]\n",
    "    y = dataset[:,0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
    "    X_train_tensor = torch.tensor(X_train, dtype = torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype = torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype = torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype = torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype = torch.float32)\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor) \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 16, shuffle = True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 16, shuffle = False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83cbe5d0-beac-475d-9f65-b94b068e1ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1540448f0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1584c66f0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_data_function(\"all_stocks_5yr.csv\")\n",
    "window_data = data_prep_function(data, window_size = 10)\n",
    "df = matrix_formatting_and_normalize_dataset(window_data)\n",
    "feature_target_modeling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7cc6d9-1990-4901-9353-fa3cdec407a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
